# Who is Caleb?

**Name:** Caleb Newton
**Current Status:** Student (Spring 2026)
**Age/Year:** College student (USC)
**Location:** Southern California

---

## Identity Goal

Become an AI/ML engineer who can read real papers and extract signal (not gibberish), starting with **Attention Is All You Need** and **NeRF**.

---

## What I Already Know (Baseline)

### High School Academics (San Marino High School)
**AP Courses Taken**:
- AP Calculus BC
- AP Statistics
- AP Computer Science A
- AP Computer Science Principles (CSP)
- AP Chemistry (Mrs. Chubbuck)
- AP Government
- AP Macroeconomics

**Other Courses**:
- English 7-8 (Mrs. Johns)
- San Marino HS partnership with Caltech (Electrical Engineering sector)

**Academic Achievements**:
- AP Scholar with Distinction
- Letter of Commendation from National Merit Scholarship Program
- Titan Athletic Scholar List
- Multiple 100% scores in coursework
- First 2 students in Caltech EE research program from San Marino HS

### USC Fall 2025 Semester (Freshman - Iovine & Young Academy)
**Completed Courses**:
- **ACAD-274**: Designing Interactive Data Systems
  - Data visualization and interactive design
  - Web development (HTML, CSS, JavaScript)
  - jQuery and database systems
  - SQL and PHP
  - Multiple 100% assignment scores
- **TAC-259**: AI/Machine Learning
  - Neural Networks and Deep Learning
  - TensorFlow and PyTorch
  - Computer Vision (CNN)
  - Recurrent Neural Networks (LSTM, RNN)
  - Worked with MNIST, Titanic, Iris datasets
- **GESM**: Philosophy/Theory Seminar
  - Nietzsche, Hegel, Hölderlin
  - Weber, Freud, Einstein, Schmitt, Weil
  - Critical theory and philosophical foundations

**Personal Website**: calebnewton.me (portfolio site built in ACAD course)

### Spring 2026 Courses (Current)
- Multivariable Calculus
- Linear Algebra
- C++ (CSCI 103)
- Discrete Methods in CS

### Coding Skills
**Languages & Frameworks**:
- **Python**: Intermediate/Advanced (FastAPI, PyTorch, NumPy, sklearn)
- **JavaScript/TypeScript**: React, React Native, Node.js, Expo
- **HTML/CSS**: Proficient (built multiple full sites)
- **C++**: Currently learning (CSCI 103)
- **SQL**: Database design and queries (ACAD-274)
- **PHP**: Backend development (ACAD-274)
- **jQuery**: Interactive web development

**Development Experience**:
- Built Screen Fighter (full-stack Chrome extension + web app)
- Cal Hacks voice agent (React + LiveKit + Claude API)
- AINATECH AlgRun GUI (FastAPI backend, React frontend)
- DoGood/Fight (React Native mobile app - failed but shipped)
- Personal portfolio website (calebnewton.me)

**Development Skills**:
- Comfortable reading docs and learning tools quickly
- Can ship and debug independently
- Version control (Git/GitHub)
- API integration (OpenAI, Claude, Firebase)
- WebSocket real-time communication
- Docker containerization
- CI/CD with GitHub Actions
- Cloud deployment (Vercel, AWS S3)

**Tools & Platforms**:
- VSCode, Jupyter Notebooks
- Firebase (authentication, database)
- Vercel (deployment)
- AWS S3 (storage)
- MuJoCo (robotics simulation from Caltech)
- Do-mpc, MATLAB (from Caltech research)

### ML/AI Baseline
**Completed Training**:
- **TAC-259 (USC)**: Neural Networks, Deep Learning, CNNs, RNNs, LSTMs, TensorFlow, PyTorch
- **PyTorch Course**: Tensors, training loops, CNNs, custom datasets, DataLoaders, GPU basics
- **AINATECH Training**: 3D Gaussian Splatting, COLMAP, depth estimation, CUDA optimization

**ML Concepts**:
- ML workflow habits (splits, baselines, evaluation)
- Python/NumPy/sklearn fundamentals
- Computer vision (CNNs, image classification)
- 3D reconstruction and neural rendering
- Depth estimation and multi-view geometry

**Production ML Experience**:
- AlgRun pipeline (COLMAP, 4DGS, depth estimation)
- CUDA kernel profiling and optimization
- GPU memory management and multi-GPU systems
- Real-time rendering and performance optimization

---

## Priority Order (Locked)

1. **Primary:** Research engineering
2. **Secondary:** Systems and performance
3. **Tertiary:** Full stack and platform

---

## 2026 Goals

### Technical Readiness (By End of May)
- Be genuinely competitive for DE, Applied ML, and SWE-ML internships
- At least 6 finished Big Projects (3 in January: 16TechPersonalities, FoodVisionMini, ModelLab + 3 core: RankForge, TransformerRank, Mini-NeRF, ideally 7 with Mini-ML-Platform)
- Portfolio site with clean READMEs and reproducible runs

### Summer 2026
- AINATECH work (separate from this plan)
- Continue technical continuity (22-30 hrs/week outside AINATECH)

### Fall 2026
- Optional: potentially ready to join a different startup
- Keep light recruiting pipeline alive

### Spring/Summer 2027
- Competitive for Big Tech/FAANG + actually smart AI/ML/DE companies and labs

---

## Learning Philosophy

### Focus Areas
- **70% ML/DL:** Core machine learning and deep learning
- **30% DE-for-ML:** Pipelines, data quality, orchestration, monitoring

### No API-Wrapper Identity
- Calling APIs is fine sometimes
- But flagship work must include training and evaluating own models on real datasets

### Theory Requirement
- Focus on work where theory matters
- Optimization, probability-as-used, representations, ranking metrics, transformers, 3D
- Full stack is only a tool

---

## Time Budgets

### Spring (Jan-May 2026)
- **Target:** 25+ hours per week of out-of-class build and learn time
- Adjust week-to-week for exams but keep weekly shipping rule intact

### Summer (Jun-Aug 2026)
- **Target:** 22-30 hours per week outside AINATECH
- About 3.1-4.3 hours per day

### Fall (Sep-Nov 2026)
- **Target:** 25-35 hours per week
- About 3.6-5.0 hours per day

### Winter (Dec 2026)
- **Target:** 22-30 hours per week
- About 3.1-4.3 hours per day
- **No drift to 1-2 hours per day**

---

## Non-Negotiables

1. **Ship-first override:** If Doc 1 weekly ship is at risk, pause optional work
2. **Weekly shipping rule:** Every week ends with something merged and documented
3. **No API-wrapper identity:** Train and evaluate your own models
4. **Failure modes taxonomy:** Every Big Project documents failures (data, objective/metric, model/representation, optimization, systems/infra, human/UX)
5. **What would change my mind:** Every major claim includes uncertainty statement
6. **Intellectual honesty:** Say "I don't know" when appropriate
7. **Evaluation rigor:** Baselines, metrics, CIs, slicing, failure writeups

---

## Big Projects (10 Core + 1 Optional)

### January Complete Builds (Week 1-2)
0a. **16TechPersonalities** (January Week 1-2) - Full-stack personality assessment app (Next.js + TypeScript + React + Supabase)
0b. **FoodVisionMini** (January Week 1-2) - Computer vision food classifier with transfer learning (PyTorch + CNNs)
0c. **ModelLab** (January Week 1-2) - Full-stack ML tool with FastAPI + Docker + CI/CD

### Core Portfolio Projects (Feb-May)
1. **RankForge** (Feb-May) - Ranking/recommendation with retrieval
2. **TransformerRank** (Mar-May) - Transformer-based ranking with LoRA
3. **Mini-NeRF** (Mar-May) - Neural Radiance Fields reproduction
4. **Mini-ML-Platform** (Optional if ahead by May)

### Post-May Continued Shipping Set
5. **PolicyRank** (Jun-Jul) - Bandits/RL for ranking
6. **RetrievalScale** (Aug-Sep) - Retrieval depth + data scale
7. **ModelOpsKit** (Oct-Nov) - ML systems maturity, reliability
8. **Mini-RAGLab** (Optional, Nov) - GenAI developer skill

---

## Special Projects

### StateLab (Feb-May, Flagship Overlay)
- **Purpose:** Makes you legible as research engineer for stateful memory, attention efficiency, and frontier labs
- **Phase A (Feb):** Attention efficiency benchmarking suite
- **Phase B (Mar):** Minimal stateful reactive loop with async update
- **Phase C (Apr-May):** Frontier-grade eval layer + scale runs + research-style report

---

## North Star Question
To be locked by end of March 2026. Will tie together RankForge + TransformerRank + Mini-NeRF with a coherent research narrative.

---

## Tech Stack

### Core ML/DL
- Python, PyTorch, scikit-learn, XGBoost/LightGBM
- Hugging Face (must ship at least one model to HF Hub)
- FAISS and/or HNSWlib for ANN

### Data/DE
- SQL (Postgres), Pandas, DuckDB, Parquet
- Spark (introduced April/May)
- Airflow core

### Full Stack (January Sprint Only)
- TypeScript + Next.js + React
- FastAPI + Supabase
- Vercel deployment

### MLOps & Systems
- Docker + Docker Compose
- GitHub Actions CI
- W&B or MLflow (lock by end of February)
- Great Expectations or pandera (lock by end of February Week 6)

---

## Weekly Operating Loop

### Sunday (Planning Block - 45 min)
- Review last week's shipped artifact
- Pick this week's one ship artifact
- Pick one learning goal and one rep
- Write acceptance criteria (metric + plot + 5-sentence takeaway)

### Mon-Sat (Daily)
- **Ship block:** 90-120 minutes
- **Learn block:** 60-90 minutes
- **Review and notes:** 30 minutes

### Wednesday (Midweek Check - 15 min)
- If ship artifact not on track → cut scope immediately

### Friday (Ship Window - 2-3 hrs)
- Merge, tag, update README
- Save /artifacts bundle
- Push new plot or benchmark table

### Saturday (Red-team + Retro - 45 min)
- Break evaluation/serving with one adversarial case
- Log one failure mode entry
- Write one sentence: what changed my mind this week

---

## Interview Prep (Separate from Main Work)

Lives in **Doc 2**. Must not break shipping (Doc 1 wins).

### Cadence
- **Weeks 1-6:** 3 items/day (Tue/Thu: 1 SQL + 2 DSA)
- **Weeks 7-14:** 2 items/day (Tue/Thu: 1 SQL + 1 DSA)
- **Weeks 15-19:** Interview mode (3 items/day + 2 mocks/week)
- **Weeks 20+:** Maintenance (2 items/day)

### Pattern Coverage
Arrays/hash, two pointers, sliding window, stacks, binary search, linked lists, trees, heaps, backtracking, tries, graphs, DP, greedy, intervals, math/geometry, bit manipulation

### SQL Practice
DataLemur every Tuesday and Thursday

---

## Company Targeting (13 Categories)

1. Stateful/memory/reactive (RxAI, Liquid AI)
2. Foundation model builders (OpenAI, Anthropic, DeepMind, Meta AI, Mistral, xAI, Cohere, AI21)
3. Compute/compilers/inference (NVIDIA, Groq, Cerebras, Together AI, Fireworks, Modal)
4. Data-centric/training infra (Scale, Snorkel, Databricks/MosaicML, W&B, Labelbox)
5. Agent infrastructure (Hugging Face, LangChain, LlamaIndex, Pinecone, Modular, Vercel AI)
6. Reasoning-first/agentic (Imbue, Cognition, Adept, Reflection, Fixie, Ultravox, Intrinsic)
7. Continuous learning (Lemma, Lilt, Numenta, Sana, Elicit, Humanloop)
8. Search/knowledge (Perplexity, Exa, Consensus, Primer, AI2, You.com, Scite)
9. Healthcare/life sciences (Insilico, insitro, Atomwise, Isomorphic, Recursion)
10. Healthcare-safe/regulated (Hippocratic, Tandem, Qventus, Notable, Abridge)
11. Enterprise workflow AI (Netic, Kavida, Harvey, RelationalAI, Glean)
12. Voice/multimodal (ElevenLabs, Hume, Deepgram, AssemblyAI, Inflection, Character.AI, Replika)
13. Creative/spatial/world-model (Runway, Wonder Dynamics, Inworld, Pika, Luma, AINATECH)

---

## Context for Claude

When helping Caleb:

1. **Assume competence** - He can ship and debug independently
2. **Focus on research engineering** - Not just coding, but understanding theory and papers
3. **Respect the priority order** - Research > Systems > Full-stack
4. **Ship-first mindset** - If something breaks weekly shipping, adjust immediately
5. **Evaluation rigor matters** - Always include baselines, metrics, failure modes
6. **No hand-holding on basics** - He's comfortable with docs and tools
7. **Theory when it matters** - Explain optimization, probability, representations when relevant
8. **Week Walkthroughs are primary** - Main learning path, other folders are supporting

---

Last updated: January 22, 2026
